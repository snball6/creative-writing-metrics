---
title: "Creative Writing Data Analysis"
author: "Sarah Ball"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(out.width = "100%")
library(zoo) #TODO: as.Date conflict
install.packages("tidyverse")
library(tidyverse)
library(knitr)
library(kableExtra)

timesheet <- read.csv("data/core_writing_data.csv")
timesheet$date <- as.Date(timesheet$Day, format = "%m/%d/%Y")
#todo - possible data cleaning, collapse+combine totals for same day/cat/etc rows - know of only one repeat, but with times added in the future there will be more

#update new column assignment operators to consistently be <-

#this file is intentionally not included in the repo for privacy reasons
schedule <- read.csv("data/combined_workday_schedule.csv") 
schedule$date <- as.Date(schedule$date, format = "%Y-%m-%d")

#fill in skip days to create a continuous timeseries
timesheet_complete <- timesheet %>%
  filter(!is.na(date)) %>%
  complete(date = seq(min(date), max(date), by = "day"), fill = list(Hours = 0, Time = "N/A", Category = "N/A", Project = "N/A", Sub.Project = ""))

reduct_c = "#b6ddf6"
base_color = "#7AA6C2"
highlight_c = "#004c6d"

```

\<Placeholder for opening graphic - possible weekly hours bar chart?\>

# Summary

With dual degrees in Writing and Computer Science, I have always loved using data to inform my craft. What began as simple word-count tracking of my creative fiction writing, evolved in 2023 into a detailed timesheet that tracked my hours per project—a practice inspired by my software development work at Menlo Innovations.

For this project, I applied my analytical and technical skills to my creative writing process to identify trends or insights present in my historical metrics that I could use to inform my writing habits going forward.

I created visualizations to help contextualize the numbers, enriched my findings with additional data sources to expand the narrative, ran what if scenarios to identify experiments to run, and ultimately created a live dashboard for tracking my progress.

# Quick Links

Looking for examples of how I used specific tools or technologies? Follow these links to jump to the relevant section:

-   [**Spreadsheets**](#spreadsheets) - pivot tables, charts, and formulas

-   [**Python & Data Cleaning**](#python-and-data-cleaning) - python script used to extract, clean, and visualize supplemental schedule data

-   <todo>**R** - this web page was made using R Markdown and most of the plots were made using the ggplot2 library

-   <todo>**Tableau** - I made a live dashboard to track my 2026 goals

# Main Data Structure

My creative writing timesheet is tracked in a Google Sheets and there are five fields:

-   Day - when the writing occurred. There can be multiple entries for the same day logged against different projects (such as August 10th in the example below)

-   Hours - [active writing time](#active-writing-time "Details on what hours I count") tracked in [15 minute increments](#why-15-minutes "Why 15 minutes") or 0.25 of an hour

-   Category - broad [categorization](#category-explanation "What each category means") about the type of writing activity

-   Project - a shortened title of the story

-   Sub Project - an optional field to group specific efforts on a project

![](images/timesheet_screenshot.png){style="border: 2px solid #595959; padding: 5px; border-radius: 4px; display: block; margin: auto;" width="500"}

Prior to this analysis project, my primary way of visualizing this information and benchmarking my progress was through pivot tables and charts in Google Sheets. For details, see [Spreadsheets](#spreadsheets) in the appendix.

# The Goal {#the-goal}

TODO: all time monthly chart

My goal for this project was to identify ways to increase my writing productivity without setting myself an unrealistic or unattainable goal.

Last year, going into 2025, I had set myself the goal of writing at least an hour most days, that is a mode of 1 hour or higher. I thought it was a safe increase to push myself towards given my success in 2024. Surely, my productivity could just keep going up? But in execution, 2025 fell far short of that goal.

TODO: mark mode and median differently

```{r 2024 histogram, fig.height=4, fig.width=12}
y_24_25_date_grouped <- timesheet_complete %>%
  filter(year(date) == 2024 | year(date) == 2025) %>%
  group_by(date) %>%
  summarise(sum_hours = sum(Hours))

y_24_25_date_grouped$year_s <- format(y_24_25_date_grouped$date, "%Y")
y_24_25_date_grouped$highlight <- ifelse(
                  # mark 2024 mode and median
                  (year(y_24_25_date_grouped$date) == 2024 &
                     (y_24_25_date_grouped$sum_hours == 0.5 |   
                        y_24_25_date_grouped$sum_hours == 1.25)) |
                  # mark 2025 mode and median
                    (year(y_24_25_date_grouped$date) == 2025 &
                     (y_24_25_date_grouped$sum_hours == 0.25 |   
                        y_24_25_date_grouped$sum_hours == 0.5)),
                              "Highlighted", "Normal")

facet_labeller <- as_labeller(c(
  "2024" = "2024 - Mode: 0.50 and Median 1.25",
  "2025" = "2025 - Mode: 0.25 and Median 0.50"
))

ggplot(y_24_25_date_grouped, aes(x = sum_hours, fill=highlight)) +
  geom_histogram(
    binwidth = 0.25,
    boundary = 0,
    closed = "left",
    color = "#FFFFFF",
    show.legend = FALSE
    ) +
  facet_wrap(~ year_s, labeller = facet_labeller) +
  coord_cartesian(xlim = c(0, 8)) +
  scale_fill_manual(values = c("Highlighted" = highlight_c, "Normal" = base_color)) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 15)
    ) + 
  labs(
    title = "Distribution of writing session length",
    x = "Hours written",
    y = "Number of days"
  ) 

```

# Behind the Data

To better inform why 2025 fell short of that goal, let me unpack and contextualize my high output year.

![](images/placeholder_timeline.png){style="border: 2px solid #595959; padding: 5px; border-radius: 4px; display: block; margin: auto;" width="680" height="240"}

```{r annotated timeline, fig.height=4, fig.width=12}
timeline <- read.csv("data/timeline_annotated.csv")
timeline$date <- as.Date(timeline$Day, format = "%m/%d/%Y")
timeline_complete <- timeline %>%
  filter(!is.na(date)) %>%
  complete(date = seq(min(date), max(date), by = "day"), fill = list(Hours = 0, Category = "N/A", Project = "N/A", Sub.Project = "", Timeline.category = ""))

custom_colors <- c("9 none" = "#B0B0B0",
"5 Sorceress 2nd" = "#444e86",
"8 1st draft attempt" = "#5886a5",
"7 Raven 1st" = "#955196",
"6 Sorceress 3rd" = "#ff6e54",
"4 Sorceress 4th - R & R" = "#faa600",
"3 Raven 2nd" = "#dd5182",
"2 Sorceress 5th" = "#01976C",
"1 Katarin 1st" = "#97014B",
"0 Katarin 2nd" = "#015697")

  timeline_complete %>%
  # aggregate by month
  mutate(year_month = floor_date(date, "month")) %>%
  group_by(year_month, Timeline.category) %>%
  summarise(total_hours = sum(Hours), .groups = "drop") %>%
  # plot
  ggplot(aes(x = year_month, y = total_hours,  fill=Timeline.category)) +
  geom_col(color = "#ffffff", show.legend = FALSE) +
  scale_fill_manual(values = custom_colors) +
  labs(title = "Monthly Total Hours",
       x = "",
       y = "") +
  theme_minimal() +
  scale_x_date(
    date_breaks = "1 month",
    date_labels = "%b %Y",  
    expand = expansion(mult = c(0, 0))
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

**2023:**

-   [Jan 2023 - Sorceress 2nd]{style="background-color:#444e86; color:#FFFFFF; padding:5px; border-radius: 10px"} - I finished the 2nd draft of my Sorceress project and sent out queries to literary agents seeking representation.

-   [1st Jul 2023 - draft attempt]{style="background-color:#5886a5; color:#FFFFFF; padding:5px; border-radius: 10px"} - I started writing a brand new story, but lost steam part way in.

-   [Sep 2023 - Raven 1st]{style="background-color:#955196; color:#FFFFFF; padding:5px; border-radius: 10px"} - I decided to participate for the first time in [National Novel Writing Month](https://en.wikipedia.org/wiki/National_Novel_Writing_Month) and used the challenge of 50k words in 30 days to tackle a project I had attempted several times before, but had never finished a full draft. In the months before, I wrote a new outline and the opening chapters. In November, I accomplished the 50k goal, and kept going until the manuscript was finished December 9th for a total of 85k words in 80 days!

-   [Dec 2023 - Sorceress 3rd]{style="background-color:#ff6e54; color:#FFFFFF; padding:5px; border-radius: 10px"} - Fresh off that success, I decided to do another rewrite on my Sorceress manuscript and attempt another round of querying.

**2024:**

-   [Jan - Sorceress 4th - R&R]{style="background-color:#faa600; color:#FFFFFF; padding:5px; border-radius: 10px"} - An agent reached out with interest in the story. She gave me some suggested changes and requested I revise and resubmit. I invested all the free time I had in getting the edits in and resubmitted in under two months. Unfortunately, the agent decided not to sign the project.

-   [Mar - Raven 2nd]{style="background-color:#dd5182; color:#FFFFFF; padding:5px; border-radius: 10px"} - Though disappointed about Sorceress, I was eager to dive back into the Raven manuscript and start the 2nd draft.

-   [Jul - Sorceress 5th]{style="background-color:#01976C; color:#FFFFFF; padding:5px; border-radius: 10px"} - I decided to give the Sorceress project one more revision and round of queries. Receiving only form rejections, I decided to shelve the manuscript.

-   [Oct - Katarin 1st]{style="background-color:#97014B; color:#FFFFFF; padding:5px; border-radius: 10px"} - For my 2nd year participating in NaNoWriMo, I worked on a much shorter project and managed the 50k goal in 23 days!

-   [Dec - Raven 2nd]{style="background-color:#dd5182; color:#FFFFFF; padding:5px; border-radius: 10px"} - I was into the thick of the Raven rewrite. Not the fun and exciting opening chapters, but the messy middle where I needed to address plot gaps, character motivations, and point of view.

**2025:**

-   [Feb, May, and Jun - Pauses]{style="background-color:#dd5182; color:#FFFFFF; padding:5px; border-radius: 10px"} - In order to focus on career certification, a job search, and later adjusting to a new job, I put my daily writing habit on pause.

-   [Jul - Raven 2nd]{style="background-color:#dd5182; color:#FFFFFF; padding:5px; border-radius: 10px"} - I resumed my daily writing habit again, but was still working on tricky parts of the manuscript.

-   [Oct - Katarin 2nd]{style="background-color:#015697; color:#FFFFFF; padding:5px; border-radius: 10px"} - Instead of a NaNoWriMo rough draft, I decided to spend November working on Katarin's 2nd draft, and kept going on it through the end of the year.

**So in summary:**

-   In 2023, I was just getting into the swing of writing on a daily basis and gained momentum through NaNoWriMo going into the next year.

-   In 2024, I worked on highly engaging projects like my Sorceress 4th and 5th drafts, the early stages of my Raven 2nd draft, and a quick rough draft.

-   In 2025, I worked almost exclusively on the harder stages of the Raven 2nd draft with several breaks to accommodate life events in the first half of the year. My hours increased some when I began work on the Katarin 2nd draft.

# Building a Model Year

Given the differences, instead of taking 2024 as-is for my model year, I decided to use it as only a starting point and approximate a better model by correcting for expected differences between 2024 and my anticipated 2026.

## Category Impact

The first high-impact factor was the type of writing I was doing in 2024. It is easier for me to have longer writing sessions when working on 3rd and later drafts. Much of the writing time is spent rereading existing chapters to validate for consistency and continuity. 2nd drafts, by contrast, are high-intensity and I often need frequent breaks. I would compare 3rd+ drafts to a long walk and 2nd drafts to a sprint that is also sometimes uphill.

TODO: standardize how I label median

```{r category histogram 2024, fig.height=3, fig.width=12}

cat_hist <- timesheet_complete

first_median = median(cat_hist$Hours[cat_hist$Category == "1st Draft"], na.rm = TRUE)
second_median = median(cat_hist$Hours[cat_hist$Category == "2nd Draft"], na.rm = TRUE)
third_plus_median = median(cat_hist$Hours[cat_hist$Category == "3rd+ Draft"], na.rm = TRUE)
query_median = median(cat_hist$Hours[cat_hist$Category == "Querying"], na.rm = TRUE)
free_write_median = median(cat_hist$Hours[cat_hist$Category == "Free Write"], na.rm = TRUE)

facet_labeller <- as_labeller(c(
  "1st Draft" = sprintf("1st Draft - Median %.2f", first_median),
  "2nd Draft" = sprintf("2nd Draft - Median %.2f", second_median),
  "3rd+ Draft" = sprintf("3rd+ Draft - Median %.2f",third_plus_median)
))

cat_hist %>%
  filter(Category %in% c("2nd Draft", "3rd+ Draft")) %>%
  ggplot(aes(x = Hours)) +
  geom_histogram(
    binwidth = 0.25,
    boundary = 0,
    closed = "left",
    color = "#FFFFFF",
    fill="#7AA6C2",
    show.legend = FALSE,
    position = 'identity',
    aes(y = after_stat(density * width)) #probability percent
    ) +
  labs(
    title = "Normalized distribution of writing session length - 2023 through 2025",
    x = "Hours written",
    y = "Percentage of total"
  ) +
  theme_minimal() +
  facet_wrap(~ Category, labeller = facet_labeller)
```
Because I do not plan to work on a 3rd or later drafts in 2026, I replaced all my 3rd+ writing draft sessions in the model with my median 2nd draft writing session length of 0.75.

I also identified three outlier writing sessions in the query category.

```{r query 2024, fig.height=3, fig.width=12}


cat_hist %>%
  filter(Category %in% c("Querying") & year(date) == 2024) %>%
  ggplot(aes(x = Hours)) +
  geom_histogram(
    binwidth = 0.25,
    boundary = 0,
    closed = "left",
    color = "#FFFFFF",
    fill="#7AA6C2",
    show.legend = FALSE,
    position = 'identity',
    ) +
  labs(
    title = "Distribution of querying writing session length - 2024",
    x = "Hours written",
    y = "Count of Days"
  ) +
  theme_minimal()
```
While I usually spend between a quarter and a half hour on querying every few weeks maintaining a list of potential agents for the projects I am working on, it would be unusual for me to spend any longer sessions on the task in 2026 unless I was working on querying material for a specific project. Since I do not plan to do so, I also replaced these days writing sessions with my 2nd draft median.

TODO: address 1st draft plans

```{r category corrected, fig.height=3, fig.width=12}
model_year <- timesheet_complete %>%
  filter(year(date) == 2024)

model_year$cat_adjust_hours = ifelse(
                                (model_year$Category == "3rd+ Draft") |
                                (model_year$Category == "Querying" &
                                   model_year$Hours > 2), 
                                             0.75, model_year$Hours)

model_year$cat_adjust_diff = model_year$Hours - model_year$cat_adjust_hours

model_year %>%
  # pivot long so I can stack adjusted and diff
  pivot_longer(
    cols = c(cat_adjust_hours, cat_adjust_diff),
    names_to = "hour_set",
    values_to = "split_hours"
  ) %>%
  # aggregate by month
  mutate(month = floor_date(date, "month")) %>%
  group_by(month, hour_set) %>%
  summarise(
    total_hours = sum(split_hours), 
    .groups = "drop") %>%
  # plot
  ggplot(aes(x = month, y = total_hours, fill = hour_set)) +
  geom_col(color = "#ffffff"
           ) +
  scale_fill_manual(
    values = c("cat_adjust_hours" = base_color, "cat_adjust_diff" = reduct_c),
    labels = c("cat_adjust_hours" = "Updated model", "cat_adjust_diff" = "Reduction")
    ) +
  labs(title = "Monthly Total Hours",
       x = "",
       y = "") +
  theme_minimal() +
  scale_x_date(
    date_breaks = "1 month",
    date_labels = "%b %Y",  
    expand = expansion(mult = c(0, 0))
  )

```

## Schedule Changes

Another complicating factor to my data set was my work schedule. In 2024, I was working a 4 day a week schedule at Menlo Innovations. In April 2025, I switched to a 5 day schedule at Quantum Signal AI. To adjust my model year, I wanted to calculate my median weekday versus weekend writing session length, while also considering outliers in the data.

\<TODO - get monthly labels\>

```{r daily_scatter, fig.height=3, fig.width=12}

# group by day - across categories
model_year_daily <- model_year %>%
  group_by(date = floor_date(date, unit ="day")) %>%
  summarise(
    total_original_hours = sum(Hours),
    cat_adjust_hours = sum(cat_adjust_hours),
    .groups = 'drop') %>%
  mutate(
    day_of_week = weekdays(date),
    # Calculate days to add to reach Sunday - weekday 0
    # If the current day is Sunday (0), add 0 days. If Saturday (6), add 1 day, etc.
    week_ending = date + (7 - as.numeric(format(date, "%w"))) %% 7,
  )
  

model_year_daily %>%
  ggplot(aes(x = date, y = total_original_hours)) +
  geom_point(color = base_color) +
  labs(title = "Daily writing session length - 2024 actuals",
       x = "",
       y = "Hours") +
  theme_minimal()+
  scale_x_date(
    date_breaks = "1 month",
    date_labels = "%b %Y",  
    expand = expansion(mult = c(0, 0))
  )

```
As you can see in the above, my writing hours are highly variable from day-to-day. I knew that the spike up to 8 hours in June 2024 occurred during a vacation week focused almost exclusively on creative writing, but I did not know how many other high or low writing days were on vacation or sick days. 

To determine this I enriched my data set with information about my work schedule. For more on how I sourced and cleaned my schedule data from my old Menlo timesheets, see [**Python & Data Cleaning**](#python-and-data-cleaning).

This data enrichment helped me confirm that paid leave days in general--both sick days and vacation days--included highly variable data. With these days excluded I could calculate my median weekend and weekday writing speed.

```{r schedule histogram 2024, fig.height=3, fig.width=12}

# Added granularity ultimately no needed - consolidated PTO types
schedule <- schedule %>% 
  mutate(schedule_type = case_when(
    schedule_category == "holiday" ~ "paid leave",
    schedule_category == "sickday" ~ "paid leave",
    schedule_category == "vacation" ~ "paid leave",
    schedule_category == "weekend" ~ "weekend",
    schedule_category == "workday" ~ "workday",
  ))

merged <- left_join(model_year_daily, schedule, by ="date")
# Added PTO granularity ultimately not needed

pto_median = median(merged$total_original_hours[merged$schedule_type == "paid leave"], na.rm = TRUE)
weekend_median = median(merged$total_original_hours[merged$schedule_type == "workday"], na.rm = TRUE)
weekday_median = median(merged$total_original_hours[merged$schedule_type == "weekend"], na.rm = TRUE)


facet_labeller <- as_labeller(c(
  "paid leave" = sprintf("Paid Leave - Median %.2f", pto_median),
  "workday" = sprintf("Workday - Median %.2f", weekday_median),
  "weekend" = sprintf("Weekend - Median %.2f", weekend_median)
))

merged %>%
  ggplot(aes(x = total_original_hours)) +
  geom_histogram(
    binwidth = 0.25,
    boundary = 0,
    closed = "left",
    color = "#FFFFFF",
    fill = base_color,
    show.legend = FALSE,
    position = 'identity',
    aes(y = after_stat(density * width)) #probability percent
    ) +
  facet_wrap(~ schedule_type, labeller = facet_labeller) +
  labs(
    title = "Distribution of writing session length - 2024 actuals",
    x = "Hours written",
    y = "Percentage of total"
  ) +
  theme_minimal()
```
TODO: revisit wishy-washy part of this

Because my weekend habit is usually to spend one day heavily focused on chores and life admin tasks, my weekend writing productivity usually varies. So instead of just replacing all Fridays or Sundays, I selected the highest of the three to replace with my workday median of 1.25.

```{r schedule corrected, fig.height=3, fig.width=12}
# pivot out for week-wise logic
temp <- model_year_daily %>% 
  pivot_wider(
    id_cols = week_ending,
    names_from = day_of_week, 
    values_from = cat_adjust_hours) %>% 
  mutate(day_to_adjust = case_when (
     Friday > 1.25 
     & Friday >= Saturday 
     & Friday >= Sunday ~ "Friday",
     Saturday > 1.25 
     & Saturday >= Friday 
     & Saturday >= Sunday ~ "Saturday",
     Sunday > 1.25
     & Sunday >= Friday 
     & Sunday >= Saturday ~ "Sunday",
     TRUE ~ "None"
))

# overwrite with adjusted values
temp$Friday <- ifelse(temp$day_to_adjust == "Friday", 1.25, temp$Friday)
temp$Saturday <- ifelse(temp$day_to_adjust == "Saturday", 1.25, temp$Saturday)
temp$Sunday <- ifelse(temp$day_to_adjust == "Sunday", 1.25, temp$Sunday)

# pivot back to tall
temp <- temp %>%
  pivot_longer(
    cols =  c("Monday", "Tuesday", 
              "Wednesday", "Thursday" , 
              "Friday" , "Saturday" , "Sunday"),
    names_to = "day_of_week",
    values_to = "sched_adjusted_hours"
  )

days_from_sun <- c("Monday"=6, "Tuesday"=5, "Wednesday"=4, "Thursday"=3, 
             "Friday"=2, "Saturday"=1, "Sunday"=0)
temp$date <- temp$week_ending - days_from_sun[temp$day_of_week]

model_year_daily <- merge(model_year_daily, temp[, c("date", "sched_adjusted_hours")], by = "date")

model_year_daily$sched_adjust_diff = model_year_daily$cat_adjust_hours - model_year_daily$sched_adjusted_hours

model_year_daily %>%
  pivot_longer(
    cols = c(sched_adjusted_hours, sched_adjust_diff),
    names_to = "hour_set",
    values_to = "split_hours"
  ) %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month, hour_set) %>%
  summarise(
    total_hours = sum(split_hours),
    .groups = "drop") %>%
  ggplot(aes(x = month, y = total_hours, fill = hour_set)) +
  geom_col(color = "#ffffff") +
  scale_fill_manual(
    values = c("sched_adjust_diff" = reduct_c, "sched_adjusted_hours" = base_color),
    labels = c("sched_adjusted_hours" = "Adjusted Hours", "sched_adjust_diff" = "Reduction")
    ) +
  labs(title = "Monthly Total Hours",
       x = "",
       y = "") +
  theme_minimal()

 
# model_year_daily %>%
#   pivot_longer(
#     cols = c(sched_adjust_hours, sched_adjust_reduction),
#     names_to = "hour_set",
#     values_to = "split_hours"
#   ) %>%
#   mutate(month = floor_date(date, "month")) %>%
#   group_by(month, hour_set) %>%
#   summarise(
#     total_hours = sum(split_hours), 
#     .groups = "drop") %>%
#   ggplot(aes(x = month, y = total_hours, fill = hour_set)) +
#   geom_col(color = "#ffffff",
#            position = position_stack(reverse = TRUE)
#            ) +
#   scale_fill_manual(
#     values = c("sched_adjust_reduction" = reduct_c, "sched_adjust_hours" = base_color),
#     labels = c("Adjusted Hours", "Reduction")
#     ) +
#   labs(title = "Monthly Total Hours",
#        x = "",
#        y = "") +
#   theme_minimal()
```

## Model Year Review

With both sets of adjustments in place, you can see the resulting adjustments between 2024 and my model year--complete with my June vacation which was spent on 2nd draft work and remained as is. \<weekly view also means I now have trailing partial weeks start/end of year throwing off calcs...

```{r model year review, fig.height=3, fig.width=12}

model_year_monthly <- model_year_daily %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month) %>%
  summarise(
    orig_hours = sum(total_original_hours), 
    adj_hours = sum(sched_adjusted_hours), 
    .groups = "drop")

ggplot(model_year_monthly, aes(x = month, y = orig_hours)) +
  geom_col(color = "#ffffff",
           fill = base_color
           ) +
  ylim(0, 80) +
  labs(title = "2024 Original Total Hours",
       x = "",
       y = "") +
  theme_minimal() 

ggplot(model_year_monthly, aes(x = month, y = adj_hours)) +
  geom_col(color = "#ffffff",
           fill = base_color
           ) +
  ylim(0, 80) +
  labs(title = "Adjusted Model Year Total Hours",
       x = "",
       y = "") +
  theme_minimal() 

baseline_total = sum(model_year_monthly$orig_hours, na.rm=TRUE)
baseline_weekly_average = baseline_total / 366 * 7 #2024 was a leap year


adjusted_total = sum(model_year_monthly$adj_hours, na.rm=TRUE)
adjusted_weekly_average = adjusted_total / 366 * 7 
```

With both sets of adjustments in place, my model year consists of \<todo - should I round to .25 or not? and have the incremental build up to the new number?\>

|              | 2024   | Reduction | Model  |
|:-------------|:-------|:----------|:-------|
| Yearly total | 554.25 | -122      | 432.25 |
| Weekly mean  | 10.60  | -2.33     | 8.27   |

405.25

When I have been primarily featuring my data in a monthly cadence up to this point to show larger trends, I zoomed into a weekly level for my goals as I have found that to be an easier target \<wordsmith revisit - \>

# What ifs

To identify experiments I could run to hit my model year goal, I ran what if scenarios against my lower productivity 2025 data set to see which experiment might have allowed me to hit my model year output.

```{r 2025 daily baseline, fig.height=3, fig.width=12}

y_25_daily <- timesheet_complete %>%
  filter(year(date) == 2025) %>%
  group_by(date) %>%
  summarise(
    total_orig_hours = sum(Hours), 
    .groups = "drop") %>%
  mutate(
    # Calculate days to add to reach Sunday - weekday 0
    # If the current day is Sunday (0), add 0 days. If Saturday (6), add 1 day, etc.
    week_ending = date + (7 - as.numeric(format(date, "%w"))) %% 7
  )

baseline_total = sum(y_25_daily$total_orig_hours, na.rm=TRUE)
baseline_weekly_average = baseline_total / 365 * 7 

```

1)  No Skip Days What if I had maintained my writing streak and written my minimum of 0.25 all days. I skipped writing 57 days in 2025 - the bulk of them during a period from January to February, and another period from May to June.

```{r Skip Days, fig.height=3, fig.width=12}

y_25_daily$skip_adjust_hours = ifelse(y_25_daily$total_orig_hours == 0, 
                                             0.25, y_25_daily$total_orig_hours)

y_25_daily$skip_adjust_change = y_25_daily$skip_adjust_hours - y_25_daily$total_orig_hours 

y_25_daily %>%
  pivot_longer(
      cols = c(skip_adjust_hours, skip_adjust_change),
      names_to = "hour_set",
      values_to = "split_hours"
  ) %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month, hour_set) %>%
    summarise(
      total_hours = sum(split_hours),
      .groups = "drop") %>%
  ggplot(aes(x = month, y = total_hours, fill = hour_set)) +
  geom_col(color = "#ffffff"
           ) +
  scale_fill_manual(
    values = c("skip_adjust_change" = highlight_c, "skip_adjust_hours" = base_color),
    labels = c("Change", "Adjusted Hours")
    ) +
  labs(title = "No Skip Days",
       x = "",
       y = "") +
  theme_minimal()

skip_total = sum(y_25_daily$skip_adjust_hours, na.rm=TRUE)
skip_weekly_average = skip_total / 365 * 7 

```

2)  Half Hour Minimum What if I had maintained my streak and also written at least 0.5 hours each day?

```{r Half Hour Min, fig.height=3, fig.width=12}

y_25_daily$min_adjust_hours = ifelse(y_25_daily$total_orig_hours < 0.5, 
                                             0.5, y_25_daily$total_orig_hours)

y_25_daily$min_adjust_change = y_25_daily$min_adjust_hours - y_25_daily$total_orig_hours 

y_25_daily %>%
  pivot_longer(
      cols = c(min_adjust_hours, min_adjust_change),
      names_to = "hour_set",
      values_to = "split_hours"
  ) %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month, hour_set) %>%
    summarise(
      total_hours = sum(split_hours),
      .groups = "drop") %>%
  ggplot(aes(x = month, y = total_hours, fill = hour_set)) +
  geom_col(color = "#ffffff"
           ) +
  scale_fill_manual(
    values = c("min_adjust_change" = highlight_c, "min_adjust_hours" = base_color),
    labels = c("Change", "Adjusted Hours")
    ) +
  labs(title = "Half Hour Minimum",
       x = "",
       y = "") +
  theme_minimal()

min_total = sum(y_25_daily$min_adjust_hours, na.rm=TRUE)
min_weekly_average = min_total / 365 * 7 

```

3)  Two Writing Days What if I wrote at least 1.5 hours on at least two days a week?

Currently, I often hit that threshold on Wednesdays when I attend a weekly writing meetup. What if I had a second day set aside to extra writing time? To approximate this, I took all weeks that did not already have at least 2 days meeting the criteria, and updated either the Wednesday, Saturday, or both days to meet the 2 day requirement.

```{r Twice Weekly, fig.height=3, fig.width=12}
#  note partial weeks at start and end of year already met criteria so no 
#  special casing was needed to prevent adding hours for a day in 2024 or 2026

twice <- y_25_daily %>% 
  mutate(
    day_of_week = weekdays(date),
    # Calculate days to add to reach Sunday - weekday 0
    # If the current day is Sunday (0), add 0 days. If Saturday (6), add 1 day, etc.
    week_ending = date + (7 - as.numeric(format(date, "%w"))) %% 7
  ) %>%
  pivot_wider(
    id_cols = week_ending,
    names_from = day_of_week, 
    values_from = total_orig_hours)

threshold <- 1.5

twice$weekly_count <- apply(twice[, c("Monday", "Tuesday", 
                                      "Wednesday", "Thursday" , 
                                      "Friday" , "Saturday" , "Sunday")],
                            1, function(row) sum(row >= threshold, na.rm = TRUE))
twice$adjust <- ifelse(twice$weekly_count < 2, TRUE, FALSE)

#assign Wednesdays
twice$Wednesday <- ifelse(twice$adjust & twice$Wednesday <= threshold, threshold, twice$Wednesday)

#reassess remaining
twice$weekly_count <- apply(twice[, c("Monday", "Tuesday", 
                                      "Wednesday", "Thursday" , 
                                      "Friday" , "Saturday" , "Sunday")],
                            1, function(row) sum(row >= threshold, na.rm = TRUE))
twice$adjust <- ifelse(twice$weekly_count < 2, TRUE, FALSE)
#assign Saturdays
twice$Saturday <- ifelse(twice$adjust & twice$Saturday <= threshold, threshold, twice$Saturday)

#pivot back to tall
twice <- twice %>%
  pivot_longer(
    cols =  c("Monday", "Tuesday", 
              "Wednesday", "Thursday" , 
              "Friday" , "Saturday" , "Sunday"),
    names_to = "day_of_week",
    values_to = "twice_adjusted_hours"
  )

days_from_sun <- c("Monday"=6, "Tuesday"=5, "Wednesday"=4, "Thursday"=3, 
             "Friday"=2, "Saturday"=1, "Sunday"=0)
twice$date <- twice$week_ending - days_from_sun[twice$day_of_week]

y_25_daily_with_twice <- merge(y_25_daily, twice[, c("date", "twice_adjusted_hours")], by = "date")
y_25_daily_with_twice$twice_adjust_change <- y_25_daily_with_twice$twice_adjusted_hours - y_25_daily_with_twice$total_orig_hours 


y_25_daily_with_twice %>%
  pivot_longer(
      cols = c(twice_adjusted_hours, twice_adjust_change),
      names_to = "hour_set",
      values_to = "split_hours"
  ) %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month, hour_set) %>%
    summarise(
      total_hours = sum(split_hours),
      .groups = "drop") %>%
  ggplot(aes(x = month, y = total_hours, fill = hour_set)) +
  geom_col(color = "#ffffff"
           ) +
  scale_fill_manual(
    values = c("twice_adjust_change" = highlight_c, "twice_adjusted_hours" = base_color),
    labels = c("Change", "Adjusted Hours")
    ) +
  labs(title = "Two Writing Days",
       x = "",
       y = "") +
  theme_minimal()

twice_total = sum(y_25_daily_with_twice$twice_adjusted_hours, na.rm=TRUE)
twice_weekly_average = twice_total / 365 * 7

```

```{r Twice Weekly alts, fig.height=3, fig.width=12}
#  note partial weeks at start and end of year already met criteria so no 
#  special casing was needed to prevent adding hours for a day in 2024 or 2026

twice <- y_25_daily %>% 
  mutate(
    day_of_week = weekdays(date),
    # Calculate days to add to reach Sunday - weekday 0
    # If the current day is Sunday (0), add 0 days. If Saturday (6), add 1 day, etc.
    week_ending = date + (7 - as.numeric(format(date, "%w"))) %% 7
  ) %>%
  pivot_wider(
    id_cols = week_ending,
    names_from = day_of_week, 
    values_from = total_orig_hours)

threshold <- 1.5

twice$weekly_count <- apply(twice[, c("Monday", "Tuesday", 
                                      "Wednesday", "Thursday" , 
                                      "Friday" , "Saturday" , "Sunday")],
                            1, function(row) sum(row >= threshold, na.rm = TRUE))
twice$adjust <- ifelse(twice$weekly_count < 3, TRUE, FALSE)

#assign Wednesdays
twice$Wednesday <- ifelse(twice$adjust & twice$Wednesday <= threshold, threshold, twice$Wednesday)

#reassess remaining
twice$weekly_count <- apply(twice[, c("Monday", "Tuesday", 
                                      "Wednesday", "Thursday" , 
                                      "Friday" , "Saturday" , "Sunday")],
                            1, function(row) sum(row >= threshold, na.rm = TRUE))
twice$adjust <- ifelse(twice$weekly_count < 3, TRUE, FALSE)
#assign Saturdays
twice$Saturday <- ifelse(twice$adjust & twice$Saturday <= threshold, threshold, twice$Saturday)

#reassess remaining
twice$weekly_count <- apply(twice[, c("Monday", "Tuesday", 
                                      "Wednesday", "Thursday" , 
                                      "Friday" , "Saturday" , "Sunday")],
                            1, function(row) sum(row >= threshold, na.rm = TRUE))
twice$adjust <- ifelse(twice$weekly_count < 3, TRUE, FALSE)

#assign Sundays
twice$Sunday <- ifelse(twice$adjust & twice$Sunday <= threshold, threshold, twice$Sunday)

#pivot back to tall
twice <- twice %>%
  pivot_longer(
    cols =  c("Monday", "Tuesday", 
              "Wednesday", "Thursday" , 
              "Friday" , "Saturday" , "Sunday"),
    names_to = "day_of_week",
    values_to = "twice_adjusted_hours"
  )

days_from_sun <- c("Monday"=6, "Tuesday"=5, "Wednesday"=4, "Thursday"=3, 
             "Friday"=2, "Saturday"=1, "Sunday"=0)
twice$date <- twice$week_ending - days_from_sun[twice$day_of_week]

y_25_daily_with_twice <- merge(y_25_daily, twice[, c("date", "twice_adjusted_hours")], by = "date")
y_25_daily_with_twice$twice_adjust_change <- y_25_daily_with_twice$twice_adjusted_hours - y_25_daily_with_twice$total_orig_hours 

twice_total = sum(y_25_daily_with_twice$twice_adjusted_hours, na.rm=TRUE)
twice_weekly_average = twice_total / 365 * 7
print(twice_total-288)

```

4)  Writing Vacations What if I took time off from work with the express purpose of spending a large portion of that day writing?

For this one, I did not create a chart, but rather tables to assessed the potential impact.

Given `n` number of writing vacations days and `h` additional hours worked on those days The total yearly increase would be `h * n` And the weekly mean change as a result would be `h * n / 365 * 7`

The resulting tables:

![](images/placeholder_writing_vacations.png)

## The results

![](images/Comparisons.png)

# The Plan:

Based on all of the above, I decided to set my 2026 goals to be: Maintain a daily writing streak without skip days ? Write a minimum of 1 hour twice a week (No set days - but this will likely be one weekend day and Wednesdays--since I attend a weekly writing meet up that day) ?

I chose not to set an overarching grand-total for the year goal because I have found those lag metrics less motivating. For example, if I set a goal of reading "100 books a year", then have a month where I fall behind, it can make the rest of the year feel like a demotivating scramble to catch up. But if my goal is to read "about 2 books a week", I can always start a new week and feel like I am getting back on track with a lead-metric habit.

I anticipate life events in 2026 might interrupt my habits like they did in 2025, so I am focusing on the small controllable targets on a weekly and monthly cadence.

## Tracking Dashboard:

I create a Tableau Dashboard to give me a clear set of visuals to benchmark my progress on my goals.

As of the time of my writing this (1/\_\_/2026), my prior weeks have not been near my new goals. Unsurprising since I had not even established the goals yet--and had focused most of my free time on this analysis.

Now that I have a centralized place to see how I am doing, I can make informed decisions to course correct and try new experiments if necessary.

## Further Analysis:

### Timing:

One experiment + metric that I added is not yet backed by any concrete data set: writing multiple times per day. Prior this year, I only tracked my writing time down to the day. If I wrote 1 in the morning and 0.75 in the evening, I might enter the data in my timesheet as =1+.75, but there was no indication these were two different sessions or when they happened. I might be just as likely to enter that formula if I had done an hour morning writing session--usually tracked with a simple egg-timer--then decided to attempt a second hour right after it, which I ended early. I also was not particularly careful not to copy/paste-as-value over these summarized days when transferring entries between old and new timesheet templates. The formula was only used for ease of data entry.

Which means I cannot say if my productive writing days were made out of lots of little sessions or several long sessions. If mornings were more impactful, or evenings. For 2026, I hope to prime myself to answer those questions.

I also now have a dedicated spreadsheet tracking my work schedule so I can keep using that data to inform my dashboard, rather than needing to periodically export and categorize the data from the current payroll application.

# Appendix

------------------------------------------------------------------------

## Spreadsheets {#spreadsheets}

### Google Sheets vs Microsoft Excel

I have regularly used both Sheets and Excel for work and personal projects, but chose to use Google Sheets for tracking my creative writing time because I already do all my creative writing in Google Docs. I like to do my writing from across multiple devices, which at various points has meant a linux computer, a Chromebook laptop, and an Android Phone. This naturally led me towards Google's tools over Microsoft's.

### Shared Writing Metrics

You can view a subset of writing timesheet data [here](https://docs.google.com/spreadsheets/d/1N7T_HbgdGJGohsjXLYBfF8_POvJ1bwDPgBQJ9C8o-Us/edit?usp=sharing) along with the formulas and aggregations I use to track my time. To see which fields are populated through formulas you can use the shortcut `` ctrl + ` `` or the menu options `View > Show > Formulas` to toggle on formula view.

A high level overview of some of the spreadsheet features I am using in this spreadsheet are:

**Formulas:**

-   **Importrange** - I chose to split the data I wanted to publicly share as part of this project from some of the more detailed and project-specific data I track in my timesheet--such as extra notes, word count, pages into a rewrite, and less-polished charts. I still wanted the shared sheet to include live data, rather than a snapshot, so I am importing the core metrics from my live spreadsheet into this shared document.

-   **Countif**, **if, or, today** - On the "Skip Days" tab of the sheet, I am generating a full list of dates starting in 2023 to today and creating fill value rows for days I did not write.

-   **Sort, vstack, filter -** To join the core writing day in with the skip days in the "Skip Days Added" tab, I am using **vstack**. I use **filter** to remove the blank space rows generated by formulas in my core data set, and I use another **filter** to only stack in those days that are skipped days. Lastly, for easier readability, I **sort** everything in ascending order.

-   **Weekday -** I like to track my writing week from Monday to Sunday so that a single weekend's effort falls in the same week. I use the **weekday** formula and **if** to calculate the Sunday week ending date.

-   **Xlookup -** I wanted to give an honorable mention to my favorite spreadsheet formula, even though it does not appear in my shared document. Introduced to Excel in 2019 and Sheets in 2022, this upgrade to **vlookup** is super powerful and I've used it often. I used **vlookup** heavily in my publishing job to aggregate error report data by book ISBN and often use **xlookup** for similar tasks where I want to match up two data sets. For this project, my creative writing data does not have a single unique key I could use for lookups. Because there can be multiple entries per date and if I had **xlookup** instead of **vstack** to join in my writing data with skip days, I would have lost entries that were on the same day.

**Pivot Tables:**

-   The tabs "Monthly Totals", "Weekly Totals", and "Daily Writing" each contain pivot tables aggregating the data using date groups at a monthly, weekly, and daily level

-   For "Monthly Totals" I also used grouped columns to combine my smaller projects to reduce clutter for the chart of monthly writing hours by prioject.

**Charts:**

-   **Stacked bar** - Are my go-to for showing the aggregate total hours worked in a time period, while also distinguishing the different categories or projects worked on.

-   **Scatter plot** - for "Daily Totals" I used scatter to show my daily writing because of the density and high variability of the data.

-   **Histograms** - These are less-polished version of the histograms appearing [earlier](#the-goal).

-   **Combo Chart** - like xlookup, I do not have an example in the shared document, but this is another of my go-tos. For rewrite projects, I track how many pages in I am on a given day. This allows me to better visualize when I have to double back to earlier in the manuscript. I include hours written on a second access because I like seeing how the two relate to one another. Sometimes my "pages in" barely moves when I am hard at work on a difficult scene, but I can see that I was still putting in a lot of time. Below is a screenshot of what this looks like for the Raven project. In it you can see that I frequently had to double back around the 80 page mark to ensure I had the right setup for a particularly difficult scene.

## ![](images/raven_combo_chart.svg){style="border: 2px solid #595959; padding: 5px; border-radius: 4px; display: block; margin: auto;" width="500"}

## Active Writing Time {#active-writing-time}

I only count time when I am intentionally sitting down to write, rewrite, or brainstorm on a project.

I do not track time spent thinking about my writing while doing other things. For instance, going out for a walk and mulling over a problem or mentally narrating a scene during my morning commute. I do not count those times mostly because they are harder to quantify. That morning commute narration will start and stop frequently--as traffic requires more or less of my focus--and my mind will wander to plenty of other things as I walk. The precise number of minutes that were *actually* spent on writing is debatable.

However, I do not want to discount those non-active writing activities. Many of my break through decisions on a plot problem or characterization happen outside of active-writing time. As my data set grows I hope to revisit the question of the importance of non-active writing time and necessary breaks between writing session.

I would hypothesize there is an ideal ratio or at least an upper bounds of how many active hours I can put in before stepping away is necessary to make forward progress. For example, my Raven 1st draft took a total of 50 hours to complete, but that time was spread out over the course of 80 days. I do not think I would have been able to condense all that work into 2 work weeks, even if I had a clear schedule to focus only on writing for that period.

## Why 15 minutes? {#why-15-minutes}

Gathering metrics comes with a trade-off: the data entry must be easy enough to maintain, yet detailed enough to be meaningful. I chose 15 minutes in part due to my work at Menlo Innovations, where I was already practiced in tracking my time by the quarter-hour.

Interestingly, this increment also serves as a great motivator. If I am five minutes into a new quarter-hour, I’m more likely to keep writing to hit the next increment. If I’ve written for 20 minutes, I might as well push for 30.

------------------------------------------------------------------------

## Category explanation {#category-explanation}

For my timesheet, I define my categories this way:

-   1st draft - Writing the initial first draft of a story. This is a fast and quick draft with the goal to write out a version of all the scenes in order with minimal editing done as I go.

-   2nd draft - Following the first draft, all the work needed to revise it into complete, coherent, and readable state.

-   3rd+ draft - Includes 3rd and later drafts. Usually just polish or adjustments to further improve the story

-   Free write - Catch-all category for activities like writing loose scenes for side projects, doing writing exercises, or brainstorming future projects. If a story later progresses to a full 1st draft, some free write entries might get recategorized into the 1st draft category

-   Querying - Time spent preparing material to query literary agents, researching agents, and any admin or meetings that result

------------------------------------------------------------------------

## Python & Data Cleaning {#python-and-data-cleaning}

To better understand my writing habits, I wanted to add additional context about my work schedule. Were the spikes in writing productivity due to a vacation day spent writing? Were drops in productivity tied to sick days or a heavy workload?

### Data Source

For my work schedule from April 2025 forward, I could easily source this information from my employer's PTO application. I also usually include a memo line on the request distinguishing between sick days and vacation time. For those few entries missing that data, they were recent enough that I knew what category to put them in. Holidays I could pull from an informational email listing the effective holidays for the year.

For data prior April 2025, I would have to get more creative. Outs were submitted through email from an account I no longer have access to, but I do have a nearly complete copy of all my Menlo timesheets from the 2023-2025 period of interest. These timesheets do not specify which days were sick days versus planned vacation outs, but they would allow me to assemble a list days I took PTO and effective holidays.

### Timesheet structure

My Menlo timesheets are structure for human readability, not an automated import. Below is an example timesheet with the data I want to pull out marked.

![](images/annotated_menlo_timesheet.png){style="border: 2px solid #595959; padding: 5px; border-radius: 4px; display: block; margin: auto;" width="600"}

Given the complexity of file format and the number of files (118 in total), I chose to write a python script to extract the information I needed into an easier csv format. My script needed to dynamically handle the varying number of rows and a changing layout. (During development, I found some variation in which cells were merged on the template over time). My entire python script can be found [here](https://github.com/snball6/creative-writing-metrics/blob/main/python-timesheet-parsing/timesheet_parser.py), but the parsing specifically occurs in the `parse_timesheets` function.

For the example above, my script would mark Saturday, Sunday, and Friday as weekends. Monday and Tuesday and workdays. Wednesday as PTO, and Thursday as a Holiday.

### Cleaning

After I initially parsed the data, I created a quick calendar heatmap visualization to help me validate the output. It quickly revealed some potential issues in the data. For example, it looked like I had taken three weeks of vacation in April 2024! And I saw other blank weeks that did not appear to line up with any vacations I remembered taking.

![](images/work_schedule_heatmap.svg)

I added an additional check to my script to not only list any files that failed to parse, but to also check for any missing dates in the data. The results gave me a clear list of files to manually check, and an answer to why the missing weeks were not in my failed to parse list. The timesheets for those weeks had the right date in their file name, but the wrong one in their cells, resulting in those date's values being overwritten.

Because I wanted to be able to reproduce my work, I kept a running list of all my changes to files–checked into the same repo as my parsing script and this report. I was also working on a duplicate copy of my timesheet files, so I would always have the originals available for reference or to revert my changes.

One file I knew was missing before I even started my analysis. I decided to make a placeholder best-guess timesheet to bridge that gap. Because my goal for using this data was to identify non-work days that might explain outlier writing hours, and I had already verified there were no unusually high or low writing hours that week, I decided it was sufficient to assume a regular work week schedule. 

If I had found that there was outlier data in that week or I had more missing weeks in the data set, I would have introduced an "unknown" category to help distinguish these days.

### Additional Validation

## Off day subcategories {#off-day-subcategories}

<placeholder> In my initial parsing of the data I had even more finite categories, but when reviewing the data that level of granularity did not add additional insights...

```{r paid leave histograms, fig.height=3, fig.width=12}

# Note look into the distributions different when I expand outside of 2024, but my skip day skew in 2023 might be a factor
merged <- left_join(model_year, schedule, by ="date")
merged <- merged %>% 
  mutate(schedule_type = case_when(
    schedule_category == "holiday" ~ "paid leave",
    schedule_category == "sickday" ~ "paid leave",
    schedule_category == "vacation" ~ "paid leave",
    schedule_category == "weekend" ~ "weekend",
    schedule_category == "workday" ~ "workday",
  )
)

ggplot(merged, aes(x = Hours, fill=schedule_category)) +
  geom_histogram(
    binwidth = 0.25,
    boundary = 0,
    closed = "left",
    color = "#FFFFFF",
    show.legend = FALSE,
    aes(y = after_stat(density))
    ) +
  theme_minimal() +
  labs(
    title = "2024",
    x = "Hours written",
    y = "Density"
  ) +
  facet_wrap(~ schedule_category)

```

<picture> Sick days, vacation days, and holidays were useful to identify outliers, but the distribution of each did not vary from one another as much as I had originally hypothesized. The reason for this, I believe, are two fold. For vacation days, I do not focus all my vacation days on creative writing--I might just as like be traveling or doing other activities that take up more time and result in a lower writing output. For sick days, I can think of a few occasions that might account for high output days. A typical one would be that I called out sick from work due to a migraine and spent most of the morning in bed, but if I was feeling recovered enough by early or late afternoon, I probably would spend that time writing.

\<add note about the 4 hour workday 1/3 and checking that it was in fact both a workday + a high productivity day

## What do you write? Are you published?

I write primarily fiction, usually in the adult fantasy or Sci Fi genres. I'm not published yet, but ultimately finding an agent and a traditional publisher for my books is my goal!
